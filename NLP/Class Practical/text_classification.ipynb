{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f5d2617",
   "metadata": {},
   "source": [
    "📁 Dataset Understanding & Topics (Q1–Q5)\n",
    "\n",
    "[Exploration] Load the dataset using pandas. What are the unique classes in the label column?\n",
    "[Distribution] Count the number of samples in each category. Are the classes balanced?\n",
    "[Inspection] Print the first 5 rows of the dataset. What kind of sentences are associated with each category?\n",
    "[Vocabulary] Extract all unique words from the dataset. How many distinct words are there?\n",
    "[Text Length] Calculate the average number of words per sentence in each class.\n",
    "\n",
    "🔧 Text Preprocessing (Q6–Q9)\n",
    "\n",
    "[Cleaning] Create a function to lowercase, remove punctuation, and strip whitespace from each sentence.\n",
    "[Stopwords] Remove stopwords from the text. How does this affect the total number of tokens?\n",
    "[Noise Removal] Write a function to remove numerical tokens from the sentences.\n",
    "[Preprocessing Function] Create a preprocessing function that combines cleaning, tokenization, and stopword removal.\n",
    "\n",
    "🔤 Tokenization (Q10–Q11)\n",
    "\n",
    "[Word Tokenization] Tokenize a sentence from the dataset and return a list of its tokens.\n",
    "\n",
    "🧠 POS Tagging & Chunking (Q12–Q15)\n",
    "\n",
    "[POS Tagging] Use NLTK to perform part-of-speech tagging on a sentence from the dataset.\n",
    "[Tag Distribution] What are the most common POS tags in your dataset?\n",
    "[Chunking] Apply chunking (e.g., NP chunking) on a sentence using regex grammar.\n",
    "[Named Entity] Identify named entities (like locations, organizations, people) using NLTK’s ne_chunk.\n",
    "\n",
    "🔍 Stemming & Lemmatization (Q16–Q19)\n",
    "\n",
    "[Stemming] Use a stemmer (like PorterStemmer) to stem all tokens in a sample sentence.\n",
    "[Lemmatization] Use a lemmatizer to lemmatize the same tokens. Compare the results to stemming.\n",
    "[Application] Create a column in the dataset with lemmatized versions of each sentence.\n",
    "\n",
    "🧼 Stopwords & Vocabulary Analysis (Q20–Q21)\n",
    "\n",
    "[Stopwords Impact] Remove all the stopwords from the data.\n",
    "[Feature Extraction] Use CountVectorizer or TfidfVectorizer to transform the cleaned text into numerical features. How many features (columns) are generated?\n",
    "\n",
    "📊 Text Classification Using Naive Bayes (Q22–Q25)\n",
    "\n",
    "[Model Building] Split the dataset and train a MultinomialNB classifier. What is the model’s accuracy on the test set?\n",
    "[Evaluation] Generate a classification report with precision, recall, and F1-score.\n",
    "[Confusion Matrix] Plot a confusion matrix. Which class has the highest number of misclassifications?\n",
    "\n",
    "\n",
    "Extra:\n",
    "Try using TfidfVectorizer instead of CountVectorizer. How does it affect performance?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
