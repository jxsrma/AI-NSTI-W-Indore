{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e155caaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a746e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Source</th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>User ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Confidence Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love this product!</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>2023-06-15 09:23:14</td>\n",
       "      <td>@user123</td>\n",
       "      <td>New York</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The service was terrible.</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Yelp Reviews</td>\n",
       "      <td>2023-06-15 11:45:32</td>\n",
       "      <td>user456</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This movie is amazing!</td>\n",
       "      <td>Positive</td>\n",
       "      <td>IMDb</td>\n",
       "      <td>2023-06-15 14:10:22</td>\n",
       "      <td>moviefan789</td>\n",
       "      <td>London</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm so disappointed with their customer support.</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Online Forum</td>\n",
       "      <td>2023-06-15 17:35:11</td>\n",
       "      <td>forumuser1</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just had the best meal of my life!</td>\n",
       "      <td>Positive</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>2023-06-16 08:50:59</td>\n",
       "      <td>foodie22</td>\n",
       "      <td>Paris</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Just had the most amazing vacation! I can't wa...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>2023-07-02 18:01:23</td>\n",
       "      <td>travelenthusiast1</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>The food at this restaurant was awful. Never g...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Zomato</td>\n",
       "      <td>2023-07-02 20:45:37</td>\n",
       "      <td>foodlover123</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>I can't stop listening to this song. It's my n...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Spotify</td>\n",
       "      <td>2023-07-03 09:17:52</td>\n",
       "      <td>musiclover789</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Their website is so confusing and poorly desig...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Website Review</td>\n",
       "      <td>2023-07-03 11:59:18</td>\n",
       "      <td>user789</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>I had an incredible experience at the theme pa...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Trip Report</td>\n",
       "      <td>2023-07-03 14:40:05</td>\n",
       "      <td>thrillseeker1</td>\n",
       "      <td>Orlando</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text  Sentiment  \\\n",
       "0                                I love this product!   Positive   \n",
       "1                           The service was terrible.   Negative   \n",
       "2                              This movie is amazing!   Positive   \n",
       "3    I'm so disappointed with their customer support.   Negative   \n",
       "4                  Just had the best meal of my life!   Positive   \n",
       "..                                                ...        ...   \n",
       "91  Just had the most amazing vacation! I can't wa...   Positive   \n",
       "92  The food at this restaurant was awful. Never g...   Negative   \n",
       "93  I can't stop listening to this song. It's my n...   Positive   \n",
       "94  Their website is so confusing and poorly desig...   Negative   \n",
       "95  I had an incredible experience at the theme pa...   Positive   \n",
       "\n",
       "             Source             Date/Time             User ID      Location  \\\n",
       "0           Twitter   2023-06-15 09:23:14            @user123      New York   \n",
       "1      Yelp Reviews   2023-06-15 11:45:32             user456   Los Angeles   \n",
       "2              IMDb   2023-06-15 14:10:22         moviefan789        London   \n",
       "3      Online Forum   2023-06-15 17:35:11          forumuser1       Toronto   \n",
       "4       TripAdvisor   2023-06-16 08:50:59            foodie22         Paris   \n",
       "..              ...                   ...                 ...           ...   \n",
       "91      TripAdvisor   2023-07-02 18:01:23   travelenthusiast1        Sydney   \n",
       "92           Zomato   2023-07-02 20:45:37        foodlover123        Mumbai   \n",
       "93          Spotify   2023-07-03 09:17:52       musiclover789        Berlin   \n",
       "94   Website Review   2023-07-03 11:59:18             user789       Toronto   \n",
       "95      Trip Report   2023-07-03 14:40:05       thrillseeker1       Orlando   \n",
       "\n",
       "     Confidence Score  \n",
       "0                0.85  \n",
       "1                0.65  \n",
       "2                0.92  \n",
       "3                0.78  \n",
       "4                0.88  \n",
       "..                ...  \n",
       "91               0.93  \n",
       "92               0.55  \n",
       "93               0.91  \n",
       "94               0.68  \n",
       "95               0.89  \n",
       "\n",
       "[96 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('D:\\\\EduNet\\\\NSTI Indore\\\\AI\\\\NLP\\\\Dataset\\\\Sentiment_analysis.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153ca365",
   "metadata": {},
   "source": [
    "Lower Case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59f5c0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lowercase(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefbb441",
   "metadata": {},
   "source": [
    "Remove Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5378d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('','',string.punctuation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde03ca1",
   "metadata": {},
   "source": [
    "Remove any speacial character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c590a93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_special_char(text):\n",
    "    return re.sub(r'[^a-zA-Z\\s]','',text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7323fd42",
   "metadata": {},
   "source": [
    "Remove Extra white Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d1a45d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_whitespace(text):\n",
    "    return re.sub(r'\\s+',' ',text) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e14897",
   "metadata": {},
   "source": [
    "Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ab66e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Jash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61d00f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb2d8156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4eefb02a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3aae0298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "type(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b485ae86",
   "metadata": {},
   "source": [
    "Filter Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55c19635",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Jash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Jash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import word_tokenize\n",
    "def remove_stopwords(text):\n",
    "    words = word_tokenize(text)\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Another Approach\n",
    "    # filtered_words = []\n",
    "    # for word in words:\n",
    "    #     if word not in stop_words:\n",
    "    #         filtered_words.append(word)\n",
    "        \n",
    "    return ' '.join(filtered_words)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5af402e",
   "metadata": {},
   "source": [
    "Combine All Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35dcfe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = to_lowercase(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = remove_special_char(text)\n",
    "    text = remove_extra_whitespace(text)\n",
    "    text = remove_stopwords(text)\n",
    "    return text    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb12a2f",
   "metadata": {},
   "source": [
    "Create a New Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75cdb3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>I had a frustrating experience navigating thro...</td>\n",
       "      <td>frustrating experience navigating website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>I'm disappointed with the food at this restaur...</td>\n",
       "      <td>im disappointed food restaurant tasteless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>I had a terrible experience with their deliver...</td>\n",
       "      <td>terrible experience delivery service late unpr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>This restaurant has the best food. I highly re...</td>\n",
       "      <td>restaurant best food highly recommend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Just had the best meal of my life!</td>\n",
       "      <td>best meal life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>The website is slow and unresponsive. Difficul...</td>\n",
       "      <td>website slow unresponsive difficult navigate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I can't stop listening to this song. It's my n...</td>\n",
       "      <td>cant stop listening song new favorite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>This song always puts me in a good mood. It's ...</td>\n",
       "      <td>song always puts good mood goto feelgood track</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>The food at this restaurant was outstanding. H...</td>\n",
       "      <td>food restaurant outstanding highly recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>This book made me feel inspired. Highly recomm...</td>\n",
       "      <td>book made feel inspired highly recommended</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text  \\\n",
       "28  I had a frustrating experience navigating thro...   \n",
       "39  I'm disappointed with the food at this restaur...   \n",
       "53  I had a terrible experience with their deliver...   \n",
       "46  This restaurant has the best food. I highly re...   \n",
       "83                 Just had the best meal of my life!   \n",
       "41  The website is slow and unresponsive. Difficul...   \n",
       "14  I can't stop listening to this song. It's my n...   \n",
       "40  This song always puts me in a good mood. It's ...   \n",
       "26  The food at this restaurant was outstanding. H...   \n",
       "89  This book made me feel inspired. Highly recomm...   \n",
       "\n",
       "                                         Cleaned_Text  \n",
       "28          frustrating experience navigating website  \n",
       "39          im disappointed food restaurant tasteless  \n",
       "53  terrible experience delivery service late unpr...  \n",
       "46              restaurant best food highly recommend  \n",
       "83                                     best meal life  \n",
       "41       website slow unresponsive difficult navigate  \n",
       "14              cant stop listening song new favorite  \n",
       "40     song always puts good mood goto feelgood track  \n",
       "26     food restaurant outstanding highly recommended  \n",
       "89         book made feel inspired highly recommended  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Cleaned_Text'] = df['Text'].apply(clean_text)\n",
    "df[['Text','Cleaned_Text']].sample(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
