{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8994cfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26f3cd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa994375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 7592, 3071, 1010, 2023, 2003, 8991, 9932, 2465,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Hello Everyone, This is Gen AI Class\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9a9616b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.0194,  0.0587, -0.1013,  ..., -0.2857,  0.4270,  0.5786],\n",
       "         [ 0.3468,  0.2065,  0.1249,  ..., -0.0802,  0.5390,  0.6611],\n",
       "         [-0.5564,  0.0110, -0.4079,  ...,  0.7311,  1.1838,  0.6770],\n",
       "         ...,\n",
       "         [-0.5813, -0.0888,  0.2460,  ..., -0.2753,  0.3232, -0.0591],\n",
       "         [-0.5120, -1.1093, -0.6856,  ...,  0.4046,  0.3504, -0.2283],\n",
       "         [ 0.6272, -0.2161, -0.1937,  ...,  0.2564, -0.6468, -0.1430]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.8643, -0.5323, -0.9378,  0.7974,  0.6795, -0.1440,  0.8716,  0.2948,\n",
       "         -0.8237, -1.0000, -0.3199,  0.9290,  0.9747,  0.6865,  0.9328, -0.6644,\n",
       "         -0.1407, -0.6025,  0.3621, -0.0751,  0.7248,  1.0000,  0.1639,  0.4427,\n",
       "          0.5361,  0.9855, -0.7767,  0.9326,  0.9557,  0.6540, -0.7019,  0.2134,\n",
       "         -0.9866, -0.3413, -0.9632, -0.9883,  0.3785, -0.7259, -0.1590, -0.0335,\n",
       "         -0.8821,  0.3233,  1.0000, -0.4472,  0.4125, -0.3623, -1.0000,  0.3262,\n",
       "         -0.8438,  0.9128,  0.8630,  0.8380,  0.1869,  0.4613,  0.5140, -0.1014,\n",
       "         -0.0707,  0.0863, -0.2828, -0.6152, -0.6569,  0.4918, -0.8547, -0.9113,\n",
       "          0.8507,  0.8655, -0.2682, -0.4100, -0.1371, -0.1498,  0.8952,  0.3116,\n",
       "         -0.1716, -0.8932,  0.6612,  0.4148, -0.7361,  1.0000, -0.4796, -0.9742,\n",
       "          0.9261,  0.8202,  0.6202, -0.4317,  0.7859, -1.0000,  0.5319, -0.2282,\n",
       "         -0.9873,  0.3743,  0.5932, -0.2766,  0.8679,  0.6960, -0.7649, -0.5282,\n",
       "         -0.3844, -0.8053, -0.3792, -0.4003,  0.1992, -0.3278, -0.4818, -0.4900,\n",
       "          0.2694, -0.5464, -0.3258,  0.6136,  0.1167,  0.7093,  0.5277, -0.5186,\n",
       "          0.4834, -0.9542,  0.6228, -0.4053, -0.9820, -0.6878, -0.9834,  0.6831,\n",
       "         -0.3059, -0.3060,  0.9649, -0.3127,  0.4708, -0.1833, -0.9033, -1.0000,\n",
       "         -0.6430, -0.6722, -0.4970, -0.3269, -0.9623, -0.9578,  0.6376,  0.9401,\n",
       "          0.2392,  0.9999, -0.4089,  0.9398, -0.5018, -0.7882,  0.4693, -0.5730,\n",
       "          0.8671,  0.3286, -0.5163,  0.2909, -0.2873,  0.3389, -0.7769, -0.2577,\n",
       "         -0.8325, -0.9433, -0.4018,  0.9513, -0.5773, -0.9542, -0.2881, -0.1990,\n",
       "         -0.5556,  0.8436,  0.7875,  0.4559, -0.3978,  0.5598,  0.5531,  0.6180,\n",
       "         -0.8042, -0.0983,  0.4705, -0.3240, -0.9035, -0.9747, -0.4192,  0.6039,\n",
       "          0.9864,  0.7234,  0.3281,  0.7460, -0.4379,  0.6791, -0.9469,  0.9714,\n",
       "         -0.2961,  0.4040, -0.5269,  0.5957, -0.7503,  0.3777,  0.8454, -0.6329,\n",
       "         -0.8083, -0.1808, -0.5616, -0.4397, -0.8357,  0.3122, -0.3905, -0.4310,\n",
       "         -0.1783,  0.9190,  0.9593,  0.6313,  0.4145,  0.6218, -0.8822, -0.4761,\n",
       "          0.0751,  0.2787,  0.2488,  0.9894, -0.8523, -0.1870, -0.9309, -0.9846,\n",
       "         -0.0482, -0.8290, -0.2123, -0.7742,  0.7484, -0.3805,  0.6526,  0.5054,\n",
       "         -0.9740, -0.7610,  0.3188, -0.5157,  0.5432, -0.2768,  0.7804,  0.9635,\n",
       "         -0.5941,  0.3860,  0.9611, -0.9542, -0.8147,  0.7525, -0.3647,  0.8195,\n",
       "         -0.7259,  0.9835,  0.9552,  0.7396, -0.8792, -0.8736, -0.7696, -0.7806,\n",
       "         -0.0695,  0.3907,  0.9167,  0.7161,  0.4750,  0.0238, -0.6319,  0.9917,\n",
       "         -0.8093, -0.9405, -0.6435, -0.2706, -0.9802,  0.8222,  0.3545,  0.5215,\n",
       "         -0.4726, -0.7396, -0.9439,  0.8127,  0.1110,  0.9815, -0.2971, -0.8817,\n",
       "         -0.5311, -0.9059, -0.1227, -0.3102, -0.5040, -0.1121, -0.9511,  0.4493,\n",
       "          0.4521,  0.6194, -0.8203,  0.9972,  1.0000,  0.9629,  0.8880,  0.8988,\n",
       "         -0.9999, -0.5770,  1.0000, -0.9908, -1.0000, -0.9096, -0.7083,  0.3738,\n",
       "         -1.0000, -0.2508, -0.0292, -0.8842,  0.6619,  0.9616,  0.9874, -1.0000,\n",
       "          0.7716,  0.9141, -0.7627,  0.9428, -0.5589,  0.9580,  0.5942,  0.4499,\n",
       "         -0.3873,  0.4853, -0.9659, -0.8526, -0.6791, -0.8049,  0.9990,  0.1573,\n",
       "         -0.7756, -0.9104,  0.3931, -0.1490,  0.1392, -0.9699, -0.3689,  0.3632,\n",
       "          0.7960,  0.1879,  0.3890, -0.6495,  0.3989,  0.3336,  0.3514,  0.7693,\n",
       "         -0.9384, -0.4563, -0.0436, -0.3067, -0.7645, -0.9721,  0.9631, -0.5483,\n",
       "          0.8530,  1.0000,  0.1212, -0.8631,  0.7321,  0.3087, -0.4897,  1.0000,\n",
       "          0.8351, -0.9699, -0.7100,  0.6675, -0.6169, -0.7017,  0.9995, -0.3171,\n",
       "         -0.7548, -0.3529,  0.9730, -0.9808,  0.9975, -0.8783, -0.9651,  0.9688,\n",
       "          0.9172, -0.5697, -0.6508,  0.2432, -0.8187,  0.3050, -0.9159,  0.7438,\n",
       "          0.4033, -0.1229,  0.8418, -0.6636, -0.6755,  0.3507, -0.4926, -0.1701,\n",
       "          0.9509,  0.6256, -0.3779,  0.1425, -0.4031, -0.5012, -0.9719,  0.6343,\n",
       "          1.0000, -0.3400,  0.7518, -0.5176, -0.1593, -0.0559,  0.5356,  0.6666,\n",
       "         -0.3812, -0.8668,  0.7749, -0.9475, -0.9842,  0.7219,  0.2891, -0.4345,\n",
       "          1.0000,  0.5491,  0.2875,  0.4326,  0.9803,  0.0886,  0.6390,  0.9144,\n",
       "          0.9616, -0.2891,  0.6706,  0.7372, -0.8903, -0.4002, -0.7287,  0.0980,\n",
       "         -0.9213, -0.0237, -0.9391,  0.9514,  0.9260,  0.4325,  0.3453,  0.7735,\n",
       "          1.0000, -0.6930,  0.6424,  0.3146,  0.7560, -0.9999, -0.8582, -0.4860,\n",
       "         -0.1105, -0.8716, -0.4360,  0.3681, -0.9404,  0.8409,  0.5986, -0.9895,\n",
       "         -0.9823, -0.3363,  0.8405,  0.0577, -0.9881, -0.7282, -0.6396,  0.5573,\n",
       "         -0.2708, -0.9191, -0.3529, -0.4548,  0.5597, -0.2424,  0.6829,  0.9098,\n",
       "          0.6113, -0.7845, -0.4898, -0.1894, -0.7664,  0.7215, -0.7437, -0.9404,\n",
       "         -0.2605,  1.0000, -0.4973,  0.9282,  0.7372,  0.5545, -0.1799,  0.2701,\n",
       "          0.9700,  0.3164, -0.8268, -0.7036,  0.0121, -0.4973,  0.6965,  0.5645,\n",
       "          0.8845,  0.7404,  0.8690,  0.0595, -0.1402,  0.1453,  0.9987, -0.1845,\n",
       "         -0.2611, -0.5593, -0.0608, -0.4552, -0.0129,  1.0000,  0.4075,  0.4884,\n",
       "         -0.9832, -0.9028, -0.8845,  1.0000,  0.8449, -0.6264,  0.6830,  0.6665,\n",
       "         -0.1730,  0.6870, -0.2175, -0.3642,  0.4127,  0.2784,  0.9166, -0.6295,\n",
       "         -0.9571, -0.6886,  0.4306, -0.9585,  1.0000, -0.6145, -0.2964, -0.3975,\n",
       "         -0.1438, -0.3775, -0.0438, -0.9771, -0.1450,  0.2419,  0.9486,  0.3612,\n",
       "         -0.6836, -0.8686,  0.7960,  0.7351, -0.8932, -0.9403,  0.9423, -0.9853,\n",
       "          0.6718,  1.0000,  0.3795,  0.0493,  0.2536, -0.4210,  0.3957, -0.4058,\n",
       "          0.6922, -0.9565, -0.4042, -0.3328,  0.3686, -0.0879, -0.4602,  0.7185,\n",
       "          0.3552, -0.6531, -0.7033, -0.0913,  0.4557,  0.7926, -0.3484, -0.2013,\n",
       "          0.0747, -0.1274, -0.9163, -0.3022, -0.5006, -1.0000,  0.6264, -1.0000,\n",
       "          0.4496,  0.5366, -0.1812,  0.8236,  0.5359,  0.7046, -0.6575, -0.8358,\n",
       "          0.4833,  0.7496, -0.3376, -0.3510, -0.5833,  0.4689, -0.2785,  0.2429,\n",
       "         -0.7379,  0.7984, -0.1586,  1.0000,  0.2542, -0.7331, -0.9506,  0.3252,\n",
       "         -0.3838,  1.0000, -0.7683, -0.9393,  0.5772, -0.8175, -0.8423,  0.4415,\n",
       "          0.0153, -0.8352, -0.9491,  0.9586,  0.8191, -0.6748,  0.5767, -0.4459,\n",
       "         -0.6195,  0.2276,  0.9013,  0.9828,  0.4721,  0.8174, -0.0538, -0.3503,\n",
       "          0.9637,  0.2246,  0.0350,  0.1886,  1.0000,  0.4528, -0.9259,  0.2532,\n",
       "         -0.9572, -0.2616, -0.9488,  0.3676,  0.4309,  0.8953, -0.3268,  0.9464,\n",
       "         -0.7986,  0.0150, -0.5800, -0.5580,  0.4147, -0.8850, -0.9761, -0.9753,\n",
       "          0.6107, -0.5301, -0.0405,  0.2712,  0.1152,  0.4479,  0.5610, -1.0000,\n",
       "          0.9242,  0.4987,  0.9506,  0.9487,  0.7182,  0.4684,  0.3600, -0.9767,\n",
       "         -0.9711, -0.4544, -0.2728,  0.6988,  0.6389,  0.9055,  0.4539, -0.5371,\n",
       "         -0.5839, -0.6742, -0.7177, -0.9891,  0.5800, -0.6695, -0.9201,  0.9595,\n",
       "          0.1322, -0.2089, -0.3357, -0.8519,  0.8771,  0.8188,  0.2580,  0.1301,\n",
       "          0.3417,  0.8394,  0.9390,  0.9753, -0.8985,  0.7860, -0.6344,  0.5737,\n",
       "          0.7904, -0.9414,  0.2207,  0.5273, -0.5002,  0.2941, -0.2870, -0.9473,\n",
       "          0.5782, -0.3815,  0.6041, -0.5801, -0.0347, -0.5120, -0.1321, -0.6767,\n",
       "         -0.8019,  0.7462,  0.4766,  0.8582,  0.8981, -0.1558, -0.6189, -0.0859,\n",
       "         -0.8653, -0.9079,  0.8392, -0.0645, -0.6220,  0.7651, -0.0315,  0.8774,\n",
       "          0.3022, -0.3869, -0.3467, -0.5988,  0.8693, -0.3897, -0.6110, -0.6219,\n",
       "          0.7110,  0.3533,  1.0000, -0.8525, -0.8884, -0.3132, -0.4539,  0.5538,\n",
       "         -0.5092, -1.0000,  0.3769, -0.5452,  0.8353, -0.5501,  0.8185, -0.5331,\n",
       "         -0.9731, -0.4222,  0.5674,  0.7558, -0.5728, -0.3845,  0.6459, -0.0705,\n",
       "          0.9681,  0.8687, -0.2079, -0.1501,  0.7171, -0.8131, -0.7280,  0.8877]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(**encoded_input)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "294f998a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9411e-02,  5.8708e-02, -1.0132e-01,  8.2070e-02, -3.7426e-01,\n",
       "         -3.6824e-01,  6.3075e-01,  5.6609e-01,  1.4000e-01, -5.4118e-01,\n",
       "         -2.9451e-02, -5.9278e-02,  9.3803e-03,  5.0100e-01,  2.4879e-01,\n",
       "         -3.0483e-01, -3.4500e-01,  6.0751e-01,  1.4642e-01,  7.5052e-02,\n",
       "          4.3232e-02, -4.9553e-01,  1.5549e-01,  1.1255e-01,  2.0232e-01,\n",
       "         -2.1684e-01, -2.7413e-02,  3.4848e-02,  8.8155e-02, -4.7308e-01,\n",
       "         -2.4329e-01,  2.2847e-01, -3.7028e-01,  5.2370e-02,  3.5068e-01,\n",
       "         -2.0664e-01,  1.6234e-01,  2.2818e-01,  5.7718e-02,  4.4553e-01,\n",
       "         -1.0453e-01, -3.0915e-02,  3.5829e-01, -7.2191e-03, -4.6948e-02,\n",
       "         -5.6356e-01, -3.2347e+00, -5.8575e-03, -4.2100e-01, -3.3233e-01,\n",
       "          2.8364e-01, -3.4536e-01, -7.1609e-02,  2.1343e-02,  5.9858e-03,\n",
       "          5.4120e-01, -5.2508e-01,  1.2237e-01,  1.7579e-03,  1.7841e-02,\n",
       "          1.2325e-01, -1.1106e-01, -3.5361e-02,  2.2193e-01,  6.5678e-02,\n",
       "          5.3020e-01,  2.5178e-01,  2.8476e-01, -3.1238e-01,  9.1642e-01,\n",
       "         -5.7874e-01, -1.2401e-01,  4.8833e-01,  1.4295e-01, -8.0426e-02,\n",
       "         -2.3178e-01, -4.5972e-02,  1.0914e-01, -3.0905e-01,  9.2977e-02,\n",
       "         -1.1935e-01,  4.5464e-01,  4.4856e-01, -1.0079e-01,  1.1506e-02,\n",
       "          4.4414e-01, -3.9017e-01, -5.3754e-01,  3.4704e-01,  5.9910e-01,\n",
       "         -8.3207e-02, -1.8937e-02,  1.5187e-01,  2.3538e-01,  3.3003e-01,\n",
       "          1.2708e-01,  8.2704e-02,  1.7856e-01,  1.5775e-01,  1.3145e-01,\n",
       "          5.2869e-03,  2.1942e-01,  2.9573e-01, -5.2251e-01, -3.1782e-01,\n",
       "          7.8879e-02, -9.7766e-02, -1.5723e-01, -5.3516e-02, -2.4005e+00,\n",
       "          2.4690e-01, -2.8544e-02, -3.4257e-01, -2.0564e-01, -6.4618e-01,\n",
       "          6.8613e-01,  6.8346e-01, -3.0188e-01,  1.2819e-01,  1.6400e-01,\n",
       "         -2.5063e-01,  4.3836e-01, -1.9918e-01, -3.3416e-01, -5.9390e-02,\n",
       "          5.2239e-01,  6.5299e-02, -1.9693e-01,  7.0373e-01, -5.8658e-02,\n",
       "          1.9847e-01,  3.8975e-01,  3.1533e-01,  1.0321e-01, -5.8575e-02,\n",
       "         -9.1902e-02,  3.8603e-01,  1.4670e-01, -4.9285e-01, -2.9864e-02,\n",
       "         -6.0146e-01, -6.8102e-01, -2.9183e+00,  4.2743e-01,  2.3368e-01,\n",
       "          9.6056e-02, -4.5513e-01,  6.2264e-02, -3.1574e-01,  2.7098e-01,\n",
       "         -3.4119e-02,  1.4404e-01, -5.1985e-01,  4.1094e-01, -5.4925e-02,\n",
       "          1.7323e-01, -1.7774e-01, -4.7622e-01,  4.1348e-01,  8.8296e-01,\n",
       "          3.1803e-01, -1.8393e-01, -6.4649e-02,  4.0831e-01, -4.7340e-01,\n",
       "          1.4943e-01,  5.8041e-01,  2.5658e-01,  4.2467e-02, -1.5105e-01,\n",
       "         -2.6454e-01,  6.9181e-02,  2.1895e-01, -2.7155e-02, -7.7637e-02,\n",
       "          2.2280e-01,  4.1962e-01,  1.8613e-01,  5.6147e-02, -2.5496e-01,\n",
       "         -4.0078e-01,  4.7871e-02,  1.3328e-01,  1.9878e-01,  4.9756e-01,\n",
       "         -2.4366e-01,  5.7428e-01,  5.0175e-01, -2.2215e-01,  5.6551e-01,\n",
       "         -2.5628e-01, -3.6832e-01,  1.8180e-01,  2.9450e-01,  6.9640e-01,\n",
       "          1.3545e-01,  2.6412e-01,  5.2484e-02,  1.7888e-01,  5.9778e-01,\n",
       "          4.5753e-01, -2.4648e-01,  3.4463e-02,  1.5975e-01, -2.9892e-01,\n",
       "          3.6396e+00,  2.3007e-02, -1.2177e-01,  2.1285e-02,  4.6402e-01,\n",
       "         -4.2280e-01,  1.5642e-01, -3.8415e-02, -6.6109e-03,  1.6370e-01,\n",
       "         -3.5431e-02,  3.3433e-01, -1.0939e-01, -2.8793e-01, -2.0777e-01,\n",
       "          6.3783e-01, -1.8572e-01, -3.4902e-01,  4.6067e-01, -2.6634e-01,\n",
       "          1.7943e-01,  4.9809e-01,  4.2736e-01,  1.0927e-02, -1.6166e+00,\n",
       "          1.9520e-01, -3.4111e-01,  8.9356e-02,  5.2773e-01, -1.1763e-01,\n",
       "          2.7491e-01, -1.5799e-01, -4.8842e-01,  1.8099e-01, -2.8714e-02,\n",
       "          3.9633e-01,  2.0544e-01, -1.1911e-01,  2.2488e-01, -3.3227e-01,\n",
       "          4.9720e-01,  2.0450e-01, -1.3420e-01,  5.2588e-01, -3.9694e-02,\n",
       "          6.6160e-01, -5.0349e-02, -2.4885e-04, -3.5462e-01,  3.2321e-01,\n",
       "          7.9170e-02, -9.7445e-02,  1.5123e-01, -6.7334e-01,  2.0009e-01,\n",
       "         -4.3863e-01, -1.2773e-01,  2.3368e-01,  5.8913e-02, -4.5938e-01,\n",
       "         -7.0170e-01,  3.8925e-01, -4.6389e-01,  7.9592e-02, -5.4753e-01,\n",
       "          1.3917e-01, -4.8906e-01, -1.4698e-01, -3.3086e+00,  2.8657e-01,\n",
       "         -7.4301e-02, -9.1484e-02,  3.3421e-01,  1.5979e-01, -1.1168e-01,\n",
       "          5.0495e-01, -6.3836e-02, -3.0340e-01,  4.9531e-01,  1.2615e-01,\n",
       "         -4.5821e-01,  1.8691e-01, -1.6286e-01,  1.2413e-01,  1.7232e-01,\n",
       "          7.1484e-02, -4.0177e-01, -5.7605e-01,  4.0468e-01,  2.0804e-01,\n",
       "          1.6582e-02,  5.2518e-01, -2.9705e-02, -2.2770e-02,  5.9861e-02,\n",
       "         -1.2629e-01,  2.6697e-01, -5.4427e-01,  2.3997e-01, -2.1423e-01,\n",
       "         -3.3551e-02,  1.7838e-01, -3.5909e-01, -3.2124e+00, -1.1601e-01,\n",
       "         -2.5229e-01, -7.4286e-02, -1.3154e-01,  1.3865e-01,  4.7554e-01,\n",
       "          1.3033e-01, -2.3389e-01, -4.7639e-03,  8.2503e-03,  4.6983e-01,\n",
       "          4.4967e-02,  2.1615e-01,  4.3278e-01,  4.5541e-01,  4.7309e-01,\n",
       "          1.7394e-01,  5.4489e-01,  9.8994e-02, -2.6189e-01,  3.3044e-01,\n",
       "         -1.2402e-01, -1.0860e-01,  4.3547e-01,  3.6747e-01, -2.8492e-01,\n",
       "         -1.6661e-01,  3.2226e-02, -6.9011e-02,  3.9874e-01, -1.4083e-01,\n",
       "         -1.4649e-01, -2.2565e-01, -7.3926e-01, -2.6558e-01,  3.3897e-01,\n",
       "         -1.9752e-01,  5.7831e-01, -6.6840e-02,  1.2299e-01,  8.2921e-02,\n",
       "          1.1148e-01,  3.2979e-01,  1.1146e-01,  1.3516e-01, -1.0509e-01,\n",
       "          1.1445e-01,  4.5631e-03,  4.3412e-02, -5.9060e-01, -1.7199e-01,\n",
       "          1.4747e+00, -2.0815e-01,  2.2644e-01, -1.9563e-01,  1.7676e-01,\n",
       "          4.0286e-01,  1.3704e-01,  3.3517e-01,  8.0167e-01, -2.3499e-01,\n",
       "          4.7052e-01, -3.8844e-01,  1.8643e-01, -3.8572e-01,  4.9909e-01,\n",
       "         -5.3404e-01, -2.4747e-01, -9.7063e-02,  8.8907e-02,  2.6708e-01,\n",
       "         -2.1333e-01, -1.1212e+00, -3.8959e-01,  1.9490e-01, -1.8363e-01,\n",
       "          8.9902e-02,  2.5800e-01, -2.3285e-01, -4.0153e-01, -3.3992e-01,\n",
       "         -3.8449e-01,  5.4597e-01, -6.1299e-01, -1.4381e-01,  1.4536e-01,\n",
       "         -8.0972e-02, -4.6928e-01,  1.6590e-01, -3.3400e-01,  2.5983e-01,\n",
       "         -1.8443e-02,  3.8133e-01, -9.8295e-02,  2.5961e-01,  6.7775e-01,\n",
       "         -5.7768e-01,  3.5173e-01, -1.8799e-01,  2.9171e-02,  2.4000e-02,\n",
       "         -2.6146e-01,  1.0525e-01,  2.8645e-02, -1.1267e-01, -3.6901e-01,\n",
       "          1.8723e-01,  8.0080e-02,  3.0396e-01, -5.2162e-02, -3.9898e-01,\n",
       "         -5.0500e-01,  3.7555e-01,  1.1265e+00,  2.6435e-01, -1.8084e-01,\n",
       "          7.2992e-01,  3.5512e-01,  5.0390e-01,  2.6630e-02,  2.4246e-01,\n",
       "         -7.3697e-02,  3.0074e-01, -2.5476e-01, -7.7665e-02, -3.0663e-03,\n",
       "         -2.6207e-01, -3.9339e-01, -5.3556e-01, -3.8356e-03,  9.1298e-02,\n",
       "         -6.2863e-01, -2.9100e-01,  3.8029e-01, -3.4241e-01, -9.8435e-02,\n",
       "         -2.0169e-01,  2.5694e-01, -5.6440e-02,  6.5128e-01, -2.0863e-01,\n",
       "         -4.0044e-01,  5.0860e-01, -1.6194e-01,  6.6602e-01, -1.3488e-01,\n",
       "         -2.3317e-04, -5.0545e-01,  3.9106e-01,  1.6524e-01, -5.3448e-01,\n",
       "         -5.5115e-02, -5.3494e-01,  1.9905e-01,  5.2118e-01,  1.3457e-01,\n",
       "          1.3594e-01, -5.5664e-01, -7.0640e-02,  4.8676e-01,  1.0434e-01,\n",
       "         -1.1838e+00,  3.9178e-01,  3.5871e-01,  5.6395e-02, -5.8591e-02,\n",
       "          7.4133e-03, -4.7550e-01,  4.5093e-01, -2.7028e-01,  6.6841e-01,\n",
       "         -4.2521e-01, -1.7967e-01,  7.5621e-02,  2.0647e-01, -1.6024e-02,\n",
       "          1.3769e-01,  2.0825e-01, -4.7514e-01, -2.0790e-01,  2.4569e-02,\n",
       "         -4.3308e-02,  5.0395e-01,  2.9389e-01, -8.8260e-02,  7.4834e-02,\n",
       "         -1.8597e-01, -2.0213e-01,  5.7660e-01, -4.2393e-01,  2.6497e-01,\n",
       "         -9.8745e-02, -5.7816e-01, -3.9514e-01, -4.0427e-01,  4.6726e-01,\n",
       "         -1.0449e-01,  3.2193e-02, -9.2899e-02,  5.3360e-01,  6.1657e-01,\n",
       "         -4.1822e-01,  2.6387e-01,  5.2943e-01,  2.9608e-01,  4.6369e-01,\n",
       "          3.2563e-01, -1.4018e-01,  4.0326e-01,  1.4571e-01, -5.5167e-01,\n",
       "          5.1684e-02, -2.9134e-01, -3.3819e-01, -6.2999e-01, -1.4449e-01,\n",
       "         -4.0659e-02,  2.8682e-01, -1.2593e-01, -5.5702e-01, -9.6584e-02,\n",
       "         -1.4610e-02, -3.9164e-01, -4.8381e-01, -1.8005e-01, -3.2958e-01,\n",
       "         -5.9067e-01,  2.7630e-02, -3.2901e-01, -2.7235e-01,  2.0122e-01,\n",
       "          6.1615e-01,  1.6425e-01, -8.1958e-01,  1.5941e-01, -7.7898e-01,\n",
       "          3.1880e-01,  1.9571e-01,  4.1280e-01,  3.3138e-01, -5.7793e-02,\n",
       "          1.6845e-01, -9.4340e-01, -3.2903e-01,  3.5461e-01,  5.2164e-02,\n",
       "          4.6909e-01, -7.0768e-02, -4.0984e-02, -2.9096e-01, -1.0868e-01,\n",
       "         -5.4573e-01, -3.9041e-01,  1.6163e-01,  1.4695e-01,  1.9497e-01,\n",
       "         -2.3110e-02, -2.8318e-01, -1.3016e-01, -2.1704e-01, -1.8436e-01,\n",
       "         -3.5786e-01,  3.8542e-01,  4.2336e-01,  3.7245e-01, -8.7387e-02,\n",
       "          3.9983e-01,  4.5937e-01,  2.0323e-01, -4.3531e-01, -2.7746e-01,\n",
       "         -2.2382e-01, -1.0915e-01, -1.2385e-01, -1.3750e-01,  2.9226e-01,\n",
       "         -2.2887e-01,  5.6633e-02, -3.4053e-01,  2.0167e+00,  4.4644e-01,\n",
       "          1.8731e-01,  6.1653e-02,  5.7579e-01, -1.7491e-01, -2.4047e-01,\n",
       "         -3.0838e-02, -1.5296e-01,  5.1956e-01, -2.5839e-01,  2.1498e-01,\n",
       "         -1.1124e-01,  2.8752e-01,  5.4861e-01,  2.2837e-01,  1.0833e-01,\n",
       "         -2.2893e-01, -7.4941e-01,  2.4554e-01, -2.4614e-01,  3.8905e-01,\n",
       "          1.4646e-01, -1.0439e-01,  2.0454e-02,  5.2801e-01, -3.8051e-02,\n",
       "         -7.3437e-02,  4.3862e-01,  6.7581e-01, -3.0645e-01, -3.2324e-02,\n",
       "         -2.0689e-01,  5.1097e-01, -6.4729e-01,  2.9786e-01, -4.6830e-02,\n",
       "         -5.6043e-01, -5.2720e-01,  7.0186e-05, -8.7750e-02, -4.7358e-01,\n",
       "          3.3077e-01,  1.3124e-01, -1.8032e-01,  9.0514e-01, -3.4198e-01,\n",
       "         -5.5330e-01,  4.1916e-01,  3.1725e-01, -3.8681e-02,  1.1665e-01,\n",
       "         -4.0394e-01, -2.1422e-01, -1.3638e-02, -6.1190e-01,  6.3749e-02,\n",
       "         -1.8878e-01, -1.8173e-01,  4.8767e-01, -1.4381e-02,  2.9234e-01,\n",
       "          1.3029e-01, -3.7265e-01,  2.4004e-01,  1.8983e-01, -2.7802e-01,\n",
       "          5.7393e-01,  9.5388e-02, -6.4258e-01, -9.3861e-02,  6.1566e-01,\n",
       "          7.1335e-01, -8.2379e-02,  9.5974e-02,  5.8137e-02, -2.4396e-01,\n",
       "         -3.5787e-01, -1.0486e-01, -2.7648e+00,  3.5027e-01, -5.0036e-01,\n",
       "          3.1892e-02,  2.9780e-01, -1.6852e-01,  2.2111e-01,  2.3137e-01,\n",
       "          2.0388e-01, -6.6503e-02, -2.2411e-01, -5.9424e-02,  2.3945e-01,\n",
       "         -2.3528e-02,  2.4284e-01, -8.9707e-03, -8.3997e-02, -1.3708e-01,\n",
       "         -3.7037e-01, -1.9331e-01,  6.4853e-02,  3.4433e-01, -8.3903e-02,\n",
       "          4.0480e-02, -3.2256e-01,  1.8421e-01,  1.2130e-02, -2.8153e-01,\n",
       "          3.1113e-01,  2.0615e-01,  1.3301e-02,  4.2225e-01, -2.2912e-01,\n",
       "         -4.0659e-01,  2.4005e-02, -1.8059e-01, -2.8793e-01, -2.9239e-01,\n",
       "          9.0801e-02,  1.0714e-01, -8.6945e-02,  3.9630e-01, -3.4109e-01,\n",
       "          3.5430e-01, -2.1781e-01, -1.7443e-01,  3.1044e-01, -2.9185e-01,\n",
       "          3.6825e-01, -5.0233e-01,  4.4005e-01, -2.4851e-02,  1.9586e-01,\n",
       "         -4.3831e-02,  1.9690e-01,  1.2663e-02,  2.5688e-03, -5.2121e-02,\n",
       "          8.6131e-02, -4.1198e-02,  5.0436e-02, -1.5379e-01, -2.5567e-01,\n",
       "         -1.4796e-01,  4.3835e-01, -1.1316e-01, -1.0017e-02, -5.5452e-04,\n",
       "         -3.5089e-01, -2.0827e-01, -5.0115e-02,  5.4805e-02,  2.7162e-01,\n",
       "          3.5397e-01, -2.5365e-01, -2.3254e-01,  4.6961e-01,  3.5129e-01,\n",
       "          4.3161e-01,  2.5039e-01, -4.3839e-02, -1.2141e-01, -4.6044e-01,\n",
       "          3.8981e-01,  2.8746e-01, -7.1787e+00,  5.5134e-03, -4.0890e-01,\n",
       "         -5.9236e-01,  4.0781e-02, -9.4611e-01, -1.4356e-02, -3.1586e-01,\n",
       "          2.6898e-01, -1.7312e-01, -9.2713e-02,  3.5139e-01,  1.2332e-02,\n",
       "         -2.8568e-01,  4.2698e-01,  5.7861e-01]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "token_embeddings = output.last_hidden_state\n",
    "cls_embedding = token_embeddings[:,0,:]\n",
    "cls_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe479e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae0277a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a3d5b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"Tell about India\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78e8c2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[24446,   546,  3794]]), 'attention_mask': tensor([[1, 1, 1]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b914353",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[24446,   546,  3794,    12,    52,    13,    50,    13,  2316,    11,\n",
       "           329,  4554,    11,   423,  1282,   739,  3649,  2328,   780,   286,\n",
       "           262,  3649, 15733,   287,   262,  7229,    12, 22933,  3814,    13,\n",
       "           770,   373,   262,  1339,   287,  2211,    11,   618,  2869, 26466,\n",
       "           262,  4390,  4380,   338,  2066,   286,  4969,    13,  2869,   468,\n",
       "          1201,   587,  5371,   286,   257,  2168,   286, 27817,  1028,  2258,\n",
       "         25999,    11,   351,   262,   471,    13,    50,    13,  1719,  2904,\n",
       "          6699,   326,   340,  5364,   884,  6529,    11,   290,   257,  8840,\n",
       "         12069,  1043,   645,  2370,   284,   905,   326,  2869,  5952,   884,\n",
       "          4028,    13,   887,  2869,   468,   783,  6848,   284, 11983,   287]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model.generate(inputs[\"input_ids\"], max_length=100, do_sample=True, top_k=50)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e1295d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell about India-U.S. relations, for instance, have come under increasing concern because of the increasing tensions in the Asia-Pacific region. This was the case in 2013, when Japan invaded the Democratic People's Republic of Korea. Japan has since been accused of a series of atrocities against North Koreans, with the U.S. having recently denied that it committed such acts, and a subsequent inquiry found no evidence to show that Japan conducted such actions. But Japan has now admitted to participating in\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8c281e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f06ee6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dd3c20cc3a84762b7ebc6b76ca9399a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd543aee7910495da2f8fa0390067250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2791003eab3e4f75b3643f85a1293470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57d0dbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Input Text\n",
    " \n",
    "input_text = \"summarize: input Text (100 words)\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a2fd69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"\"\"Hundreds of Indian evacuees from Iran landed in New Delhi in two flights after Tehran eased airspace amid an ongoing conflict with Israel. As the Indians landed at Delhi airport under Operation Sindhu, visibly relieved passengers broke into chants of ‘Bharat Mata ki Jai’ and ‘Hindustan Zindabad’.\n",
    "\n",
    "The first flight carried as many as 290 Indians from Iran early Friday. The second flight carrying Indian evacuees from Iran, too, landed on Saturday morning. Operation Sindhu is India's mission to evacuate citizens amid the escalating Israel-Iran conflict.\n",
    "\n",
    "Emotional returnees, including students and religious pilgrims, expressed heartfelt gratitude to the Indian government for ensuring their safe return amid the escalating Israel-Iran conflict.\n",
    "\n",
    "Tazkiya Fatima, a resident of Noida, recounted the tense situation in Iran and praised the coordination between Indian authorities.\"\"\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "169e21ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evacuees from Iran landed in New Delhi in two flights\n"
     ]
    }
   ],
   "source": [
    "# Generate Output\n",
    "outputs = model.generate(inputs[\"input_ids\"], max_length=19)\n",
    " \n",
    "# Decode and Print\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
